{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"IMPORTS\"\"\"\n",
    "import numpy as np\n",
    "from helpers import *\n",
    "from implementations import *\n",
    "from utils import *\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"LOADING RAW DATA\"\"\"\n",
    "data_path = 'dataset'\n",
    "x_tr_raw, x_te_raw, y_tr_raw, train_ids, test_ids = load_csv_data(data_path, sub_sample=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"REMOVE USELESS COLUMNS\"\"\"\n",
    "columns_to_remove = np.concatenate((range(1, 25), range(54, 56)))\n",
    "\n",
    "x_tr_remove_col = np.delete(x_tr_raw, columns_to_remove, axis=1)\n",
    "x_te_remove_col = np.delete(x_te_raw, columns_to_remove, axis=1)\n",
    "\n",
    "# Treat dk, refuse and nan the same\n",
    "x_tr_dk = replace_dk_values_with_nan(x_tr_remove_col)\n",
    "x_val_dk = replace_dk_values_with_nan(x_te_remove_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dup = 3\n",
    "deg = 5\n",
    "lambda_ = 0.0002805263157894737\n",
    "\n",
    "# Nan to mean\n",
    "x_tr_no_nan, x_val_no_nan = nan_to_mean(x_tr_dk, x_val_dk)\n",
    "\n",
    "# Standardize\n",
    "x_tr_std, x_val_std = standardize(x_tr_no_nan, x_val_no_nan)\n",
    "\n",
    "# Duplicate 1 rows to balance dataset\n",
    "x_tr_duplicated, y_tr_duplicated = duplicate_1rows(x_tr_std, y_tr_raw, dup)\n",
    "\n",
    "x_tr_full = x_tr_duplicated\n",
    "x_val_full = x_val_std\n",
    "y_tr_full = y_tr_duplicated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_poly_tr = build_poly(x_tr_full, deg)\n",
    "x_poly_val = build_poly(x_val_full, deg)\n",
    "\n",
    "tx = np.c_[np.ones((x_poly_tr.shape[0], 1)), x_poly_tr]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN = 0\n",
    "if TRAIN:   \n",
    "    w, loss = ridge_regression(y_tr_full, tx, lambda_)\n",
    "    np.savetxt(\"w.txt\", w)\n",
    "else:\n",
    "    w = np.loadtxt(\"w.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = predict(x_poly_val, w, \"gd\")\n",
    "name = \"testing run.py 2\"\n",
    "create_csv_submission(test_ids, y_pred, name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "import numpy as np\n",
    "from helpers import *\n",
    "from implementations import *\n",
    "from utils import *\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load raw data\n",
    "data_path = 'dataset'\n",
    "x_tr_raw, x_te_raw, y_tr_raw, train_ids, test_ids = load_csv_data(data_path, sub_sample=False)\n",
    "\n",
    "# Remove irrelevant columns\n",
    "columns_to_remove = np.concatenate((range(1, 25), range(54, 56)))\n",
    "\n",
    "x_tr_remove_col = np.delete(x_tr_raw, columns_to_remove, axis=1)\n",
    "x_te_remove_col = np.delete(x_te_raw, columns_to_remove, axis=1)\n",
    "\n",
    "# Set the \"don't know\" and \"refused\" values to NaN\n",
    "x_tr_dk = replace_dk_values_with_nan(x_tr_remove_col)\n",
    "x_val_dk = replace_dk_values_with_nan(x_te_remove_col)\n",
    "\n",
    "# Set the optimal hyperparameters\n",
    "dup = 3\n",
    "deg = 5\n",
    "lambda_ = 0.0002805263157894737\n",
    "\n",
    "# Replace NaN values with the mean in each feature\n",
    "x_tr_no_nan, x_val_no_nan = nan_to_mean(x_tr_dk, x_val_dk)\n",
    "\n",
    "# Standardize the features\n",
    "x_tr_std, x_val_std = standardize(x_tr_no_nan, x_val_no_nan)\n",
    "\n",
    "# Duplicate rows with label 1 to balance dataset\n",
    "x_tr_duplicated, y_tr_duplicated = duplicate_1rows(x_tr_std, y_tr_raw, dup)\n",
    "\n",
    "# Create a polynomial basis of the inputs\n",
    "x_poly_tr = build_poly(x_tr_duplicated, deg)\n",
    "x_poly_val = build_poly(x_val_std, deg)\n",
    "\n",
    "# Add intercept\n",
    "tx = np.c_[np.ones((x_poly_tr.shape[0], 1)), x_poly_tr]\n",
    "\n",
    "# Train the model if TRAIN = 1, Load w and test if TRAIN = 0\n",
    "TRAIN = 0\n",
    "if TRAIN:   \n",
    "    w, loss = ridge_regression(y_tr_duplicated, tx, lambda_)\n",
    "    np.savetxt(\"w.txt\", w)\n",
    "else:\n",
    "    w = np.loadtxt(\"w.txt\")\n",
    "    y_pred = predict(x_poly_val, w, \"gd\")\n",
    "    name = \"testing run.py 3\"\n",
    "    create_csv_submission(test_ids, y_pred, name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
